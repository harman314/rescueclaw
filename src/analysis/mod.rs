#![allow(dead_code)]
use crate::config::Config;
use crate::health::IncidentLog;
use anyhow::Result;
use std::path::Path;

/// Analyze an incident using OpenClaw's LLM
pub async fn analyze_incident(cfg: &Config) -> Result<String> {
    // Read OpenClaw provider config
    let provider_cfg = cfg.read_openclaw_providers()?;

    // Extract API configuration
    let (api_key, base_url, model) = extract_api_config(&provider_cfg)?;

    // Gather evidence
    let evidence = gather_evidence(cfg).await?;

    // Build prompt
    let prompt = build_analysis_prompt(&evidence);

    // Call LLM
    let analysis = call_llm(&api_key, &base_url, &model, &prompt).await?;

    Ok(analysis)
}

/// Format a complete incident report
pub fn format_incident_report(analysis: &str, incident: &IncidentLog, backup_id: &str) -> String {
    format!(
        r#"# ðŸš¨ Incident Report

**Timestamp:** {}  
**Backup Used:** {}

## Incident Summary

{}

## ðŸ” Root Cause Analysis

{}

## âœ… Recovery

The agent has been restored from backup `{}`. All workspace files and configuration have been rolled back to the last known good state.

## ðŸ“‹ Next Steps

1. Review the analysis above
2. Check the gateway logs for more details
3. If this was caused by a config change, validate before re-applying
4. Consider creating a checkpoint before future risky operations

---
*Generated by RescueClaw v{} at {}*
"#,
        incident.timestamp,
        backup_id,
        incident.cause,
        analysis,
        backup_id,
        env!("CARGO_PKG_VERSION"),
        chrono::Utc::now().to_rfc3339()
    )
}

/// Evidence collected for analysis
struct Evidence {
    gateway_log_tail: String,
    config_diff: String,
    recent_incidents: String,
    workspace_changes: String,
}

/// Gather all available evidence
async fn gather_evidence(cfg: &Config) -> Result<Evidence> {
    // Read gateway log tail
    let gateway_log_path = cfg.openclaw.config_path.join("gateway.log");
    let gateway_log_tail = if gateway_log_path.exists() {
        read_last_n_lines(&gateway_log_path, 100)?
    } else {
        "Gateway log not found".to_string()
    };

    // Read recent incidents
    let recent_incidents = match crate::health::recent_incidents(cfg, 5) {
        Ok(incidents) => incidents
            .iter()
            .map(|i| format!("{}: {}", i.timestamp, i.cause))
            .collect::<Vec<_>>()
            .join("\n"),
        Err(_) => "No incident history".to_string(),
    };

    // Try to diff config (compare with latest backup)
    let config_diff = extract_config_diff(cfg)
        .await
        .unwrap_or_else(|_| "Could not extract config diff".to_string());

    // Check for recent workspace changes
    let workspace_changes = check_recent_workspace_changes(cfg)
        .unwrap_or_else(|_| "Could not determine recent changes".to_string());

    Ok(Evidence {
        gateway_log_tail,
        config_diff,
        recent_incidents,
        workspace_changes,
    })
}

/// Build the analysis prompt
fn build_analysis_prompt(evidence: &Evidence) -> String {
    format!(
        r#"You are an incident analyst for an AI agent system (OpenClaw).
The agent became unresponsive and was auto-restored from backup.

Analyze the following evidence and provide:
1. Most likely root cause
2. What changed before the failure
3. Recommendations to prevent recurrence

Be concise and specific. Focus on actionable insights.

## Gateway Log (last 100 lines):
```
{}
```

## Config Changes:
```
{}
```

## Recent Incident History:
```
{}
```

## Recent Workspace Changes:
```
{}
```

Provide your analysis in clear sections: Root Cause, What Changed, and Recommendations."#,
        evidence.gateway_log_tail,
        evidence.config_diff,
        evidence.recent_incidents,
        evidence.workspace_changes
    )
}

/// Extract API configuration from OpenClaw provider config
fn extract_api_config(
    provider_cfg: &crate::config::OpenClawProviderConfig,
) -> Result<(String, String, String)> {
    let providers = provider_cfg
        .providers
        .as_ref()
        .ok_or_else(|| anyhow::anyhow!("No providers in OpenClaw config"))?;

    // Try to find OpenRouter first (cheap, works well)
    if let Some(openrouter) = providers.get("openrouter") {
        if let Some(api_key) = openrouter.get("apiKey").and_then(|v| v.as_str()) {
            return Ok((
                api_key.to_string(),
                "https://openrouter.ai/api/v1".to_string(),
                "anthropic/claude-3.5-haiku".to_string(), // Cheap and good
            ));
        }
    }

    // Try Anthropic
    if let Some(anthropic) = providers.get("anthropic") {
        if let Some(api_key) = anthropic.get("apiKey").and_then(|v| v.as_str()) {
            let model = provider_cfg
                .default_model
                .as_deref()
                .unwrap_or("claude-3-5-haiku-20241022");
            return Ok((
                api_key.to_string(),
                "https://api.anthropic.com/v1".to_string(),
                model.to_string(),
            ));
        }
    }

    // Fallback: use first available provider
    if let Some(providers_obj) = providers.as_object() {
        for (name, provider) in providers_obj {
            if let Some(api_key) = provider.get("apiKey").and_then(|v| v.as_str()) {
                let base_url = provider
                    .get("baseUrl")
                    .and_then(|v| v.as_str())
                    .unwrap_or("https://api.openai.com/v1");
                let model = provider_cfg
                    .default_model
                    .as_deref()
                    .unwrap_or("gpt-4o-mini");

                tracing::info!("Using provider '{}' for analysis", name);
                return Ok((api_key.to_string(), base_url.to_string(), model.to_string()));
            }
        }
    }

    anyhow::bail!("No valid API provider found in OpenClaw config")
}

/// Call LLM API
async fn call_llm(api_key: &str, base_url: &str, model: &str, prompt: &str) -> Result<String> {
    let client = reqwest::Client::new();

    // Build request - try OpenAI-compatible format first
    let body = serde_json::json!({
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1000
    });

    let url = format!("{}/chat/completions", base_url);

    let response = client
        .post(&url)
        .header("Authorization", format!("Bearer {}", api_key))
        .header("Content-Type", "application/json")
        .json(&body)
        .timeout(std::time::Duration::from_secs(30))
        .send()
        .await?;

    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await?;
        anyhow::bail!("LLM API error ({}): {}", status, text);
    }

    let json: serde_json::Value = response.json().await?;

    // Extract response
    let content = json["choices"][0]["message"]["content"]
        .as_str()
        .ok_or_else(|| anyhow::anyhow!("Failed to parse LLM response"))?;

    Ok(content.to_string())
}

/// Read last N lines from a file
fn read_last_n_lines(path: &Path, n: usize) -> Result<String> {
    let content = std::fs::read_to_string(path)?;
    let lines: Vec<&str> = content.lines().collect();
    let start = lines.len().saturating_sub(n);
    Ok(lines[start..].join("\n"))
}

/// Extract config diff by comparing current with backup
async fn extract_config_diff(cfg: &Config) -> Result<String> {
    // Get latest backup
    let snapshots = crate::backup::list_snapshots(cfg)?;
    if snapshots.is_empty() {
        return Ok("No backups available for comparison".to_string());
    }

    // For now, just return a placeholder
    // Full implementation would extract tar.gz, compare JSONs
    Ok("Config comparison not yet implemented".to_string())
}

/// Check for recent workspace file changes
fn check_recent_workspace_changes(cfg: &Config) -> Result<String> {
    let memory_dir = cfg.openclaw.workspace.join("memory");
    if !memory_dir.exists() {
        return Ok("Memory directory not found".to_string());
    }

    // Find most recently modified files
    let mut recent_files = Vec::new();
    if let Ok(entries) = std::fs::read_dir(&memory_dir) {
        for entry in entries.flatten() {
            if let Ok(metadata) = entry.metadata() {
                if let Ok(modified) = metadata.modified() {
                    if let Ok(elapsed) = modified.elapsed() {
                        if elapsed.as_secs() < 3600 * 24 {
                            // Modified in last 24h
                            if let Some(name) = entry.file_name().to_str() {
                                recent_files.push(name.to_string());
                            }
                        }
                    }
                }
            }
        }
    }

    if recent_files.is_empty() {
        Ok("No recent file changes detected".to_string())
    } else {
        Ok(format!("Recently modified: {}", recent_files.join(", ")))
    }
}
